{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb0ba45d",
   "metadata": {},
   "source": [
    "# Naive bayes algorithm\n",
    "\n",
    "Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable. Bayes’ theorem states the following relationship, given class variable $y$ and dependent feature vector $x_1$ through $x_n$. \n",
    "\n",
    "$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) P(x_1, \\dots, x_n \\mid y)}\n",
    "                                 {P(x_1, \\dots, x_n)}$\n",
    "                                 \n",
    "$P(x_i | y, x_1, \\dots, x_{i-1}, x_{i+1}, \\dots, x_n) = P(x_i | y)$\n",
    "\n",
    "$ P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) \\prod_{i=1}^{n} P(x_i \\mid y)}\n",
    "                                 {P(x_1, \\dots, x_n)}$\n",
    "\n",
    "$\\begin{align}\\begin{aligned}P(y \\mid x_1, \\dots, x_n) \\propto P(y) \\prod_{i=1}^{n} P(x_i \\mid y)\\\\\\Downarrow\\\\\\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n} P(x_i \\mid y),\\end{aligned}\\end{align}$\n",
    "\n",
    "$\\begin{align}\\begin{aligned}P(y \\mid x_1, \\dots, x_n) \\propto P(y) \\prod_{i=1}^{n} P(x_i \\mid y)\\\\\\Downarrow\\\\\\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n} P(x_i \\mid y),\\end{aligned}\\end{align}$\n",
    "\n",
    "\n",
    "Naive Bayes is relatively immune to overfitting . Here we have a simple hypothesis, so it can not accurately represent many complex situations. since the bias is high model exhibits low variance.\n",
    "\n",
    "\n",
    " * first we have to find the prior probabilitis for both classes and feature categories \n",
    " * then have to fing the likelihoods \n",
    " * finally the use the base theorem for finding the final probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577ad79",
   "metadata": {},
   "source": [
    "### Advantage of Naive Bayes\n",
    " * Since there are no gradients or iteration parameter updates to compute, training process and predictions are quick.\n",
    " * Naive Bayes requires a small amount of training data to estimate the test data.\n",
    " * Naive Bayes handles missing values a lot easier.\n",
    " * Model handles both continuous and discreet data.\n",
    "### Disadvantages of Naive Bayes\n",
    " * Model cannot incorporate feature interactions.\n",
    " * Model performance is affected if we have skewed training data.\n",
    " * Zero Frequency problem.\n",
    " \n",
    "### Improving the model performance\n",
    " * Zero frequency problem : There can be cases where a categorical attribute has a value that was not observed in training. In this case the model will assign zero probability and unable to make the predictions. Then we usually add 1 to every value in the frequency table. This is also known as additive smoothing.\n",
    " * Naive Bayes model performance increases if we have non correlated features. So, we can remove those features that are highly correlated using pairwise correlation.\n",
    " * Naive Bayes handles missing data. if a data instance has a missing vale it will be get ignored while computing the probabilities.\n",
    " * Its good to use log probabilities to avoid difficulty with floating point.\n",
    " * Instead of using usual normal, binomial distributions we can always try different distributions to compute the posterior probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7de0027",
   "metadata": {},
   "source": [
    "<img src=\"https://namesorts.files.wordpress.com/2019/12/playnotplay_excerpt.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544edb4a",
   "metadata": {},
   "source": [
    "## Implementing naive bayes algorithm from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3169a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "class NaiveBayes():\n",
    "    def __init__(self,X,y):\n",
    "        '''X should be a dataframe'''\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.features = list(self.X.columns)\n",
    "        \n",
    "         # making a list of unique classes\n",
    "        self.classes = list(self.y.unique())\n",
    "        # counting the total no of classes in the target feature \n",
    "        self.class_0count = list(self.y).count(self.classes[0])\n",
    "        self.class_1count = list(self.y).count(self.classes[1])\n",
    "        # finding the class probabilities        \n",
    "        self.class_proba = dict.fromkeys(self.classes)\n",
    "        \n",
    "        \n",
    "        # finding the prior probabilies of classes \n",
    "        for i in range(len(self.classes)):\n",
    "            ct = len(self.y[self.y == self.classes[i]])/len(self.y) \n",
    "            self.class_proba[self.classes[i]] = ct\n",
    "            \n",
    "        # finding the prior probabilies of categories in each feature \n",
    "        self.feature_priors = dict.fromkeys(self.features)\n",
    "        for f in self.feature_priors.keys():\n",
    "            final = dict.fromkeys(set(self.X[f]))\n",
    "            for i in final.keys():\n",
    "                count = 0 \n",
    "                for j in list(self.X[f]):\n",
    "                    if j ==i:\n",
    "                        count+=1 \n",
    "                final[i] = count/len(self.X)\n",
    "            self.feature_priors[f] = final\n",
    "    \n",
    "        \n",
    "    def fit(self):       \n",
    "        # getting the features names and target name      \n",
    "        target = self.y.name\n",
    "            \n",
    "        # creating a dictionary with features as keys \n",
    "        final_dict = dict.fromkeys(self.features)\n",
    "\n",
    "        # start looping over the features using feature index \n",
    "        for f in range(len(self.features)):\n",
    "            \n",
    "            # creating the gps list consists of uniques values for each feature \n",
    "            gps = list(self.X[self.features[f]].unique())\n",
    "            \n",
    "            # creating a dictionary for each gp  \n",
    "            gp_counts = dict.fromkeys(gps)\n",
    "            \n",
    "            for j in range(len(gps)):          \n",
    "                # getting the count of first group \n",
    "                dict_count = self.y[self.X[self.features[f]] == gps[j]].value_counts()\n",
    "                # dividing the value counts by total no of classes respectively (yes and no)\n",
    "                dc = dict.fromkeys(self.classes)\n",
    "                dc[self.classes[0]] = dict_count[self.classes[0]]/self.class_0count\n",
    "                dc[self.classes[1]] = dict_count[self.classes[1]]/self.class_1count\n",
    "                \n",
    "                # storing the counts dictionary in \n",
    "                gp_counts[gps[j]] = dc\n",
    "                         \n",
    "            # adding all the gp counts to the respective features :    \n",
    "            final_dict[self.features[f]] = gp_counts\n",
    "                    \n",
    "        # returning the final dictionary which holds the apriori probabilities \n",
    "        return final_dict\n",
    "    \n",
    "    def predict(self):\n",
    "        final_dict = NaiveBayes.fit(self)\n",
    "         \n",
    "        def pred(feature_vec):                                   \n",
    "            prob_yes = 1\n",
    "            prob_no = 1\n",
    "            for i in range(len(feature_vec)):\n",
    "                \n",
    "                # finding posterior probabilities              \n",
    "                r = final_dict[self.features[i]]  [feature_vec[i]]    [self.classes[0]]\n",
    "                prob_yes = prob_yes * r \n",
    "                prob_yes = prob_yes/ self.feature_priors[self.features[i]] [feature_vec[i]] \n",
    "                \n",
    "                g = final_dict[self.features[i]][feature_vec[i]]    [self.classes[1]]\n",
    "                prob_no = prob_no * g \n",
    "                prob_no = prob_no/ self.feature_priors[self.features[i]][feature_vec[i]] \n",
    "                \n",
    "            # multiplying with class probabilities     \n",
    "            fin_class0 = prob_yes * self.class_proba[self.classes[0]]\n",
    "            fin_class1 = prob_no * self.class_proba[self.classes[1]]\n",
    "            \n",
    "            print(fin_class0,fin_class1)\n",
    "            \n",
    "            if fin_class0> fin_class1:\n",
    "                return self.classes[0]\n",
    "            else:\n",
    "                return self.classes[1]\n",
    "        \n",
    "        preds = []\n",
    "        for row in range(len(self.X)):\n",
    "            preds.append(pred(list(self.X.iloc[row])))\n",
    "        return pd.DataFrame(preds,columns = ['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e12dd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rainy</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>overcast</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sunny</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sunny</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rainy</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rainy</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sunny</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rainy</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     weather play\n",
       "0      sunny   no\n",
       "1      sunny   no\n",
       "2   overcast  yes\n",
       "3      rainy  yes\n",
       "4      rainy  yes\n",
       "5      rainy   no\n",
       "6   overcast   no\n",
       "7      sunny   no\n",
       "8      sunny  yes\n",
       "9      rainy  yes\n",
       "10     rainy  yes\n",
       "11     sunny  yes\n",
       "12  overcast  yes\n",
       "13  overcast  yes\n",
       "14     rainy   no"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('play.csv')\n",
    "x = df[['weather']]\n",
    "y = df.play\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67590ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weather': {'sunny': {'no': 0.5, 'yes': 0.2222222222222222},\n",
       "  'overcast': {'no': 0.16666666666666666, 'yes': 0.3333333333333333},\n",
       "  'rainy': {'no': 0.3333333333333333, 'yes': 0.4444444444444444}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NaiveBayes(x,y)\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5bc0c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features =  ['weather']\n",
      "no count =  6\n",
      "yes count =  9\n",
      "classes =  ['no', 'yes']\n",
      "class_prios =  {'no': 0.4, 'yes': 0.6}\n",
      "feature_priors =  {'weather': {'rainy': 0.4, 'overcast': 0.26666666666666666, 'sunny': 0.3333333333333333}}\n"
     ]
    }
   ],
   "source": [
    "print('features = ', model.features)\n",
    "print('no count = ',model.class_0count)# no \n",
    "print('yes count = ',model.class_1count) # yes \n",
    "print('classes = ', model.classes)\n",
    "print('class_prios = ', model.class_proba) \n",
    "print('feature_priors = ', model.feature_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b91185f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6000000000000001 0.39999999999999997\n",
      "0.6000000000000001 0.39999999999999997\n",
      "0.25 0.75\n",
      "0.3333333333333333 0.6666666666666665\n",
      "0.3333333333333333 0.6666666666666665\n",
      "0.3333333333333333 0.6666666666666665\n",
      "0.25 0.75\n",
      "0.6000000000000001 0.39999999999999997\n",
      "0.6000000000000001 0.39999999999999997\n",
      "0.3333333333333333 0.6666666666666665\n",
      "0.3333333333333333 0.6666666666666665\n",
      "0.6000000000000001 0.39999999999999997\n",
      "0.25 0.75\n",
      "0.25 0.75\n",
      "0.3333333333333333 0.6666666666666665\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictions\n",
       "0           no\n",
       "1           no\n",
       "2          yes\n",
       "3          yes\n",
       "4          yes\n",
       "5          yes\n",
       "6          yes\n",
       "7           no\n",
       "8           no\n",
       "9          yes\n",
       "10         yes\n",
       "11          no\n",
       "12         yes\n",
       "13         yes\n",
       "14         yes"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0201e866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
